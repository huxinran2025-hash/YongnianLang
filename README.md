# YONG â€” The CUDA Killer

> **Compute â‰  Power. The language AI writes, not humans.**

YONG (æ°¸å¹´è¯­è¨€) is a declarative programming language designed for **AI to generate**, not humans to learn. Same 30 tokens of YONG replace 500 tokens of Python. The compiler materializes the rest.

```
 What AI writes today                    What AI should write
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ from flask import Flask...  â”‚    â”‚ struct Todo {               â”‚
â”‚ from sqlalchemy import...   â”‚    â”‚   title: string             â”‚
â”‚ app = Flask(__name__)       â”‚    â”‚   done: bool                â”‚
â”‚ Base = declarative_base()   â”‚    â”‚ }                           â”‚
â”‚ class Todo(Base):           â”‚    â”‚ @api(POST, "/todos")        â”‚
â”‚   __tablename__ = 'todos'   â”‚    â”‚ fn create(req) -> Todo {    â”‚
â”‚   id = Column(Integer...)   â”‚    â”‚   return req |> save;       â”‚
â”‚   title = Column(String...) â”‚    â”‚ }                           â”‚
â”‚   done = Column(Boolean...) â”‚    â”‚                             â”‚
â”‚   ... 40 more lines         â”‚    â”‚                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ~500 tokens                 â”‚    â”‚ ~30 tokens                  â”‚
â”‚ ~$15 per 1000 files         â”‚    â”‚ ~$1.50 per 1000 files       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**10Ã— fewer tokens = 10Ã— less GPU compute = 10Ã— less power.**

## Why This Is a CUDA Killer

CUDA's moat isn't hardware â€” it's ecosystem lock-in. But there's a bigger waste hiding in plain sight:

**The language AI writes in IS a form of compute cost.**

Every `import`, every ORM config, every route handler that AI generates is a token that burns GPU power. Billions of tokens, every day, across every AI coding assistant on the planet.

YONG eliminates the waste:

| | Python (what AI writes today) | YONG (what AI should write) |
|---|---|---|
| Todo App | ~500 tokens | **~30 tokens** |
| User Auth API | ~800 tokens | **~50 tokens** |
| SNN Chip Design | ~900 lines Verilog | **~30 lines YONG** |
| AI generation cost | 1Ã— | **0.1Ã—** |

And here's the double kill: YONG also compiles to **SNN neuromorphic hardware** at 28 pJ/spike â€” **100,000Ã— more efficient** than GPU inference.

**One language. Two kills. Generation cost down 10Ã—. Execution cost down 100,000Ã—.**

## How It Works

**Humans don't write YONG. Humans don't learn YONG.**

```
              Today's pipeline:
User â†’ "Build a todo app" â†’ AI â†’ 500 tokens Python â†’ interpreter â†’ app

              YONG pipeline:
User â†’ "Build a todo app" â†’ AI â†’ 30 tokens YONG â†’ compiler â†’ app/silicon
```

The compiler infers everything from declarations: database schema, HTTP routing, middleware, serialization, error handling â€” or LIF neurons, STDP learning, WTA competition, BRAM pipelines.

**Declare intent. Compiler materializes.**

## Quick Look

### App Dialect â€” Full-Stack in 30 Tokens

```yong
@db(table="todos")
struct Todo {
    id: uid
    text: string
    done: bool
}

@api(GET, "/todos")
fn list_todos() -> list[Todo] {
    return db.todos.all()
}

@api(POST, "/todos")
fn add_todo(text: string) -> Todo {
    return db.todos.create({ text, done: false })
}

@app(route="/")
component TodoApp {
    state todos = query(list_todos)
    view {
        Header("My Todos")
        Input(placeholder="Add...", on_enter=add_todo)
        List(todos) -> |todo| {
            Row { Checkbox(todo.done) Text(todo.text) }
        }
    }
}
```

**Compiles to**: HTML + CSS + JS + REST API + Database schema + ORM

### Hardware Dialect â€” SNN Chip in 15 Lines

```yong
network MNIST {
    layer input(784);
    layer hidden(400, type=lif, threshold=300, leak=1);
    layer output(10, type=lif, threshold=200, leak=2);

    connect input -> hidden with stdp(ltp=5, ltd=2);
    connect hidden -> output with stdp(ltp=10, ltd=4);

    config {
        weight_storage: bram
        wta_mode: enable
        homeostasis: enable
        target: zynq7020
    }
}
```

**Compiles to**: 47KB synthesizable Verilog RTL (verified on Yosys + iCE40 FPGA)

## Why AI Prefers YONG

| Feature | Why it matters for AI |
|---------|----------------------|
| **No imports** | Compiler infers dependencies from declarations. Zero wasted tokens. |
| **Decorators as directives** | `@api(POST, "/todos")` replaces 20 lines of routing + middleware + serialization. |
| **Pipe operators** | `data |> validate |> save |> emit` â€” linear flow, no nesting. AI generates in one pass. |
| **No boilerplate** | No ORM config, no app factory, no session management. Declared once, inferred everywhere. |
| **Dual compilation** | Same syntax targets web apps OR silicon. AI doesn't need to know the target. |

## Core Principles (Frozen)

| Principle | Description |
|-----------|-------------|
| **AI-First** | Designed for AI to generate, not humans to type |
| **Declarative** | Write *what*, not *how* |
| **Minimum Tokens** | Maximum semantics in minimum surface area |
| **Unit Safety** | `Time<ms> + Energy<pJ>` â†’ compile error E202 |
| **Bit-Accurate** | Same `.yong` â†’ same behavior on every backend |
| **Extensible** | Frozen core, open everything else |

## The Numbers

| Metric | NVIDIA GPU | VGO SNN (YONG-compiled) |
|--------|-----------|------------------------|
| Power per inference | ~2,700,000 pJ | **~28 pJ/spike** |
| Efficiency ratio | 1Ã— | **~100,000Ã—** |
| Lines of code | 900+ (CUDA/Verilog) | **30 (YONG)** |
| FPGA bitstream | N/A | **132 KB** |

## Project Status

| Component | Status |
|-----------|--------|
| Language Specification v4.2 | âœ… Complete |
| Compiler Specification v1.0 | âœ… Complete |
| Parser (Lexer â†’ AST â†’ IR) | âœ… Working (822 lines) |
| Native Engine (.yong â†’ GUI) | âœ… Working |
| Verilog Backend (.yong â†’ RTL) | âœ… Working (47KB output, Yosys verified) |
| VGO Brain 2.0 (NL â†’ YONG) | âœ… Working (109M param SNN) |
| FPGA Synthesis (iCE40) | âœ… Verified (132KB bitstream) |

## Documentation

| Document | English | ä¸­æ–‡ |
|----------|---------|------|
| Language Specification | [spec/language-spec.md](spec/language-spec.md) | [spec-zh/YONGè¯­è¨€è§„èŒƒ.md](spec-zh/YONGè¯­è¨€è§„èŒƒ.md) |
| Compiler Specification | [spec/compiler-spec.md](spec/compiler-spec.md) | [spec-zh/YONGç¼–è¯‘å™¨è§„èŒƒ.md](spec-zh/YONGç¼–è¯‘å™¨è§„èŒƒ.md) |

## Examples

See the [examples/](examples/) directory:

- [`hello.yong`](examples/hello.yong) â€” Hello World
- [`todo-app.yong`](examples/todo-app.yong) â€” Full-stack Todo App (30 tokens)
- [`snn-mnist.yong`](examples/snn-mnist.yong) â€” MNIST classifier SNN chip
- [`auth-api.yong`](examples/auth-api.yong) â€” Authenticated API with RBAC

## Contributing

YONG is in its early stages. We welcome contributions in:

- ğŸ§ª **Compiler implementation** â€” Help build the 5-stage pipeline
- ğŸ“ **Language design feedback** â€” File issues on the spec
- ğŸ”Œ **Backend plugins** â€” Implement new compilation targets
- ğŸ“š **Documentation** â€” Improve specs, add examples, translate

## Author

**Robert Hu** â€” Chongqing, China ğŸ‡¨ğŸ‡³  
ğŸ“§ [roberthxr@qq.com](mailto:roberthxr@qq.com)

## License

[Apache-2.0](LICENSE)

---

*Declare intent. Compiler materializes.* | *å£°æ˜æ„å›¾ï¼Œç¼–è¯‘å™¨ç‰©åŒ–ã€‚*  
*Compute â‰  Power.* | *ç®—åŠ›ä¸ç­‰äºç”µåŠ›ã€‚*  
*The writer is AI, not human.* | *å†™ä»£ç çš„æ˜¯ AIï¼Œä¸æ˜¯äººã€‚*
